{
  "permissions": {
    "allow": [
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" status)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" log --oneline -5)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" add src/pages/Dashboard.tsx src/pages/DemoWizard.tsx)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" commit -m \"$\\(cat <<''EOF''\nFix React hooks violation in Dashboard and add DemoWizard\n\nRemove console.log and inline kitchen/facilities early returns that\noccurred before useState calls, violating Rules of Hooks. Role-based\nredirects now use KitchenDashboard/FacilitiesDashboard components\nafter all hooks have been called. Copy DemoWizard.tsx from .txt source.\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" push)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" push --set-upstream origin main)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" log --oneline -3)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" add src/components/Navigation.tsx)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" commit -m \"$\\(cat <<''EOF''\nfix navigation demo button\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" log --oneline -1)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" remote -v)",
      "Bash(git push:*)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" log --oneline origin/main -3)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" status vercel.json)",
      "Bash(npx vercel:*)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" add vercel.json)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" commit -m \"$\\(cat <<''EOF''\nfix vercel.json BOM character\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" add src/pages/Dashboard.tsx)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" commit -m \"$\\(cat <<''EOF''\nFix 3 Dashboard issues: stat cards, tab filters, duplicate dropdown\n\n1. Move TimeSavedCounter from Overview tab to Key Metrics tab only\n2. Add location filter dropdown to all 6 non-overview tabs\n3. Remove duplicate \"All Locations\" from TopBar dropdown by not\n   prepending it in locationDropdownOptions \\(TopBar already adds it\\)\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" commit -m \"$\\(cat <<''EOF''\nAdd score history chart and location filter to overview tabs\n\n- Replace Score History placeholder with Recharts LineChart using\n  historicalData \\(shows 3 lines for all locations, 1 line for single\\)\n- Add location filter dropdown to both Overview tab sections\n- Issues 1 \\(stat cards\\) and 4 \\(duplicate All Locations\\) were already\n  fixed in previous commit\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "WebFetch(domain:evidly-app.vercel.app)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" commit -m \"$\\(cat <<''EOF''\nAdd item IDs to navigation links and render real QR codes\n\n- Action items now navigate with specific IDs \\(e.g. /vendors?id=valley-fire\\)\n- Vendor rows navigate with vendor IDs\n- QR Passport tab renders actual QRCodeSVG components encoding\n  https://evidly-app.vercel.app/passport/[locationId] for each location\n\nCo-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>\nEOF\n\\)\")",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(npx vite build)",
      "Bash(npm run build:*)",
      "Bash(git pull:*)",
      "Bash(git stash:*)",
      "Bash(git rebase:*)",
      "Bash(npm ls:*)",
      "Bash(timeout:*)",
      "Bash(node:*)",
      "Bash(git reset:*)",
      "Bash(ls:*)",
      "Bash(git checkout:*)",
      "Bash(npm install:*)",
      "Bash(npx tsc:*)",
      "Bash(wc:*)",
      "Bash(grep:*)",
      "Bash(git status:*)",
      "Bash(for dir in api-marketplace-publish api-rate-limiter api-token-validate api-usage-aggregate api-webhook-dispatch api-webhook-retry integration-conflict-resolver integration-data-mapper integration-health-check integration-oauth-callback integration-sync-engine)",
      "Bash(do test -f \"supabase/functions/$dir/index.ts\")",
      "Bash(echo:*)",
      "Bash(done)",
      "Bash(dir:*)",
      "Bash(powershell:*)",
      "Bash(npx create-next-app:*)",
      "Bash(npx create-next-app@latest:*)",
      "Bash(git init:*)",
      "Bash(git branch:*)",
      "Bash(where:*)",
      "Bash(supabase projects:*)",
      "Bash(supabase link:*)",
      "Bash(supabase db push:*)",
      "Bash(supabase db execute:*)",
      "Bash(supabase db dump:*)",
      "Bash(supabase --help:*)",
      "Bash(supabase migration:*)",
      "Bash(for file in 20260205193618_create_invitations_and_templates.sql 20260205194556_create_reminder_and_notification_tables.sql 20260205201922_add_temperature_and_checklist_enhancements.sql 20260205215132_add_cooldown_certifications_receiving_enhancements.sql 20260205215738_create_report_subscriptions_table.sql 20260206000001_auto_request_system.sql 20260210120000_jurisdiction_scoring_tables.sql 20260210140000_ai_copilot_tables.sql 20260210160000_benchmark_tables.sql 20260210180000_insurance_risk_tables.sql 20260210200000_iot_sensor_tables.sql 20260211000000_insurance_api_foundation.sql 20260211100000_vendor_marketplace_tables.sql 20260212000000_vendor_experience_tables.sql 20260213000000_enterprise_tenant_tables.sql 20260214000000_enterprise_expanded_tables.sql 20260215000000_sensor_platform_tables.sql 20260216000000_api_integration_tables.sql 20260217000000_training_lms_tables.sql)",
      "Bash(do grep -n \"^CREATE POLICY\" \"$file\")",
      "Bash(supabase functions deploy:*)",
      "Bash(for:*)",
      "Bash(do echo \"Deploying $f...\")",
      "Bash(supabase secrets set:*)",
      "Bash(do wc -l \"$f\")",
      "Bash(npx supabase secrets list:*)",
      "Bash(npx supabase secrets set:*)",
      "Bash(curl:*)",
      "Bash(npx vitest:*)",
      "Bash(git -C \"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\" log --oneline --all)",
      "Bash(npx supabase functions deploy:*)",
      "Bash(npx supabase:*)",
      "Bash(\"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\\\\supabase\\\\migrations\\\\20260219100000_compliance_photos.sql\" << 'ENDOFFILE'\n-- ============================================================\n-- Migration: Compliance Photos\n-- Timestamped, geotagged photo evidence for compliance proof\n-- ============================================================\n\n-- Storage bucket \\(manual step — Supabase CLI doesn't support bucket creation via SQL\\)\n-- Run in Supabase dashboard: create bucket \"compliance-photos\" with public=false\n\n-- ── compliance_photos table ─────────────────────────────────\nCREATE TABLE IF NOT EXISTS compliance_photos \\(\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid\\(\\),\n  organization_id UUID REFERENCES organizations\\(id\\) ON DELETE CASCADE,\n  location_id UUID REFERENCES locations\\(id\\) ON DELETE SET NULL,\n  \n  -- What this photo documents\n  record_type TEXT NOT NULL CHECK \\(record_type IN \\(\n    'temp_log', 'checklist', 'incident', 'vendor_delivery',\n    'equipment', 'self_audit', 'inspection', 'corrective_action', 'general'\n  \\)\\),\n  record_id UUID,  -- FK to the parent record \\(temp_logs.id, checklists.id, etc.\\)\n  \n  -- Storage\n  storage_path TEXT NOT NULL,  -- path in Supabase Storage bucket\n  thumbnail_path TEXT,\n  file_size_bytes INTEGER,\n  mime_type TEXT DEFAULT 'image/jpeg',\n  \n  -- Metadata captured at time of photo\n  captured_at TIMESTAMPTZ NOT NULL DEFAULT now\\(\\),\n  latitude DOUBLE PRECISION,\n  longitude DOUBLE PRECISION,\n  address TEXT,\n  device_info TEXT,  -- e.g. \"iPhone 15 Pro, iOS 18\"\n  \n  -- Overlay data burned into image\n  overlay_timestamp TEXT,  -- human-readable timestamp burned into photo\n  overlay_gps TEXT,        -- GPS coords burned into photo\n  \n  -- Compliance\n  caption TEXT,\n  tags TEXT[] DEFAULT '{}',\n  verified_by UUID REFERENCES auth.users\\(id\\),\n  verified_at TIMESTAMPTZ,\n  \n  -- Audit trail\n  uploaded_by UUID REFERENCES auth.users\\(id\\),\n  created_at TIMESTAMPTZ DEFAULT now\\(\\),\n  updated_at TIMESTAMPTZ DEFAULT now\\(\\),\n  deleted_at TIMESTAMPTZ  -- soft delete\n\\);\n\n-- ── Indexes ─────────────────────────────────────────────────\nCREATE INDEX idx_photos_org ON compliance_photos\\(organization_id\\);\nCREATE INDEX idx_photos_location ON compliance_photos\\(location_id\\);\nCREATE INDEX idx_photos_record ON compliance_photos\\(record_type, record_id\\);\nCREATE INDEX idx_photos_captured ON compliance_photos\\(captured_at DESC\\);\nCREATE INDEX idx_photos_uploaded_by ON compliance_photos\\(uploaded_by\\);\n\n-- ── RLS ─────────────────────────────────────────────────────\nALTER TABLE compliance_photos ENABLE ROW LEVEL SECURITY;\n\nCREATE POLICY \"Users can view photos in their org\"\n  ON compliance_photos FOR SELECT\n  USING \\(\n    organization_id IN \\(\n      SELECT organization_id FROM profiles WHERE id = auth.uid\\(\\)\n    \\)\n  \\);\n\nCREATE POLICY \"Users can insert photos in their org\"\n  ON compliance_photos FOR INSERT\n  WITH CHECK \\(\n    organization_id IN \\(\n      SELECT organization_id FROM profiles WHERE id = auth.uid\\(\\)\n    \\)\n  \\);\n\nCREATE POLICY \"Managers can update photos in their org\"\n  ON compliance_photos FOR UPDATE\n  USING \\(\n    organization_id IN \\(\n      SELECT organization_id FROM profiles WHERE id = auth.uid\\(\\)\n      AND role IN \\('executive', 'management'\\)\n    \\)\n  \\);\n\nCREATE POLICY \"Managers can delete photos in their org\"\n  ON compliance_photos FOR DELETE\n  USING \\(\n    organization_id IN \\(\n      SELECT organization_id FROM profiles WHERE id = auth.uid\\(\\)\n      AND role IN \\('executive', 'management'\\)\n    \\)\n  \\);\n\n-- ── Updated-at trigger ──────────────────────────────────────\nCREATE OR REPLACE FUNCTION update_compliance_photos_updated_at\\(\\)\nRETURNS TRIGGER AS $\nBEGIN\n  NEW.updated_at = now\\(\\);\n  RETURN NEW;\nEND;\n$ LANGUAGE plpgsql;\n\nCREATE TRIGGER trg_compliance_photos_updated_at\n  BEFORE UPDATE ON compliance_photos\n  FOR EACH ROW\n  EXECUTE FUNCTION update_compliance_photos_updated_at\\(\\);\n\n-- ── Storage policies \\(for the compliance-photos bucket\\) ─────\n-- These would be set in Supabase dashboard or via supabase storage policies\n-- INSERT: authenticated users in same org\n-- SELECT: authenticated users in same org\n-- DELETE: managers in same org\nENDOFFILE)",
      "Bash(\"C:\\\\Users\\\\newpa\\\\Downloads\\\\evidly-demo-final\\\\evidly-app-main\\\\supabase\\\\migrations\\\\20260221000000_document_classifications.sql\" << 'SQLEOF'\n-- Document AI Classification Log\n-- Tracks every AI classification attempt for quality monitoring and learning\nCREATE TABLE IF NOT EXISTS document_classifications \\(\n  id UUID PRIMARY KEY DEFAULT gen_random_uuid\\(\\),\n  organization_id UUID NOT NULL,\n  document_id UUID REFERENCES documents\\(id\\) ON DELETE SET NULL,\n  file_name TEXT NOT NULL,\n  file_type TEXT,\n  file_size INTEGER,\n  -- AI classification results\n  ai_document_type TEXT,\n  ai_document_label TEXT,\n  ai_pillar TEXT,\n  ai_vendor_name TEXT,\n  ai_service_date DATE,\n  ai_expiry_date DATE,\n  ai_confidence REAL DEFAULT 0,\n  ai_summary TEXT,\n  ai_suggested_fields JSONB DEFAULT '{}'::jsonb,\n  -- User actions\n  user_accepted BOOLEAN DEFAULT FALSE,\n  user_override_type TEXT,\n  user_override_pillar TEXT,\n  user_override_vendor TEXT,\n  -- Metadata\n  classified_by UUID REFERENCES auth.users\\(id\\),\n  classification_method TEXT DEFAULT 'ai' CHECK \\(classification_method IN \\('ai', 'manual', 'filename_only'\\)\\),\n  processing_time_ms INTEGER,\n  created_at TIMESTAMPTZ NOT NULL DEFAULT now\\(\\),\n  updated_at TIMESTAMPTZ NOT NULL DEFAULT now\\(\\)\n\\);\n\n-- Indexes\nCREATE INDEX IF NOT EXISTS idx_doc_classifications_org ON document_classifications\\(organization_id\\);\nCREATE INDEX IF NOT EXISTS idx_doc_classifications_type ON document_classifications\\(ai_document_type\\);\nCREATE INDEX IF NOT EXISTS idx_doc_classifications_confidence ON document_classifications\\(ai_confidence\\);\nCREATE INDEX IF NOT EXISTS idx_doc_classifications_created ON document_classifications\\(created_at DESC\\);\n\n-- Enable RLS\nALTER TABLE document_classifications ENABLE ROW LEVEL SECURITY;\n\n-- RLS policies: users can view and insert classifications for their organization\nCREATE POLICY \"Users can view own org classifications\"\n  ON document_classifications FOR SELECT\n  USING \\(\n    organization_id IN \\(\n      SELECT organization_id FROM user_profiles WHERE id = auth.uid\\(\\)\n    \\)\n  \\);\n\nCREATE POLICY \"Users can insert classifications for own org\"\n  ON document_classifications FOR INSERT\n  WITH CHECK \\(\n    organization_id IN \\(\n      SELECT organization_id FROM user_profiles WHERE id = auth.uid\\(\\)\n    \\)\n  \\);\n\nCREATE POLICY \"Users can update own org classifications\"\n  ON document_classifications FOR UPDATE\n  USING \\(\n    organization_id IN \\(\n      SELECT organization_id FROM user_profiles WHERE id = auth.uid\\(\\)\n    \\)\n  \\);\n\n-- Updated_at trigger\nCREATE OR REPLACE FUNCTION update_doc_classifications_updated_at\\(\\)\nRETURNS TRIGGER AS $\nBEGIN\n  NEW.updated_at = now\\(\\);\n  RETURN NEW;\nEND;\n$ LANGUAGE plpgsql;\n\nCREATE TRIGGER set_doc_classifications_updated_at\n  BEFORE UPDATE ON document_classifications\n  FOR EACH ROW\n  EXECUTE FUNCTION update_doc_classifications_updated_at\\(\\);\nSQLEOF)",
      "Bash(\"C:/Users/newpa/Downloads/evidly-demo-final/evidly-app-main/supabase/functions/classify-document/index.ts\" << 'ENDOFFILE'\nimport { createClient } from \"https://esm.sh/@supabase/supabase-js@2\";\n\nconst corsHeaders = {\n  \"Access-Control-Allow-Origin\": \"*\",\n  \"Access-Control-Allow-Headers\": \"authorization, x-client-info, apikey, content-type\",\n};\n\ninterface ClassificationResult {\n  documentType: string;\n  documentLabel: string;\n  pillar: string;\n  vendorName: string | null;\n  serviceDate: string | null;\n  expiryDate: string | null;\n  confidence: number;\n  summary: string;\n  suggestedFields: Record<string, string>;\n}\n\nDeno.serve\\(async \\(req\\) => {\n  // Handle CORS preflight\n  if \\(req.method === \"OPTIONS\"\\) {\n    return new Response\\(\"ok\", { headers: corsHeaders }\\);\n  }\n\n  try {\n    const { fileBase64, fileName, mimeType } = await req.json\\(\\);\n    \n    const apiKey = Deno.env.get\\(\"ANTHROPIC_API_KEY\"\\);\n    if \\(!apiKey\\) {\n      return new Response\\(JSON.stringify\\({ success: false, error: \"API key not configured\" }\\), {\n        status: 500, headers: { ...corsHeaders, \"Content-Type\": \"application/json\" },\n      }\\);\n    }\n\n    const isImage = mimeType.startsWith\\(\"image/\"\\);\n    const isPdf = mimeType === \"application/pdf\";\n\n    // Build the system prompt - comprehensive document type taxonomy\n    const systemPrompt = `You are a commercial kitchen compliance document classifier for EvidLY.\nYour job is to analyze uploaded documents and extract key metadata.\n\nDOCUMENT TYPES YOU KNOW:\n\nFire Safety \\(pillar: fire_safety\\):\n- hood_cleaning_cert: Hood/exhaust cleaning certificate\n- fire_suppression_report: Fire suppression system inspection \\(Ansul, Amerex, etc.\\)\n- fire_extinguisher_tag: Fire extinguisher inspection tag or certificate\n- ansul_cert: Ansul system certification\n- exhaust_fan_service: Exhaust fan service/cleaning record\n- building_fire_inspection: Building fire inspection report from fire department\n\nFood Safety \\(pillar: food_safety\\):\n- health_permit: Health department permit/license\n- food_handler_cert: Individual food handler certification card\n- food_manager_cert: Food manager certification \\(ServSafe, etc.\\)\n- haccp_plan: HACCP plan document\n- allergen_training: Allergen awareness training record\n- pest_control_report: Pest control service report\n\nVendor \\(pillar: vendor\\):\n- vendor_coi: Vendor certificate of insurance \\(COI\\)\n- vendor_licenses: Vendor business license\n- service_agreements: Service agreement or contract\n\nFacility \\(pillar: facility\\):\n- business_license: Business license from city/county\n- certificate_occupancy: Certificate of occupancy\n- grease_trap_records: Grease trap pumping/service record\n- backflow_test: Backflow preventer test report\n\nRESPOND ONLY WITH VALID JSON matching this exact schema:\n{\n  \"documentType\": \"string \\(from the list above, or 'unknown'\\)\",\n  \"documentLabel\": \"string \\(human-readable name\\)\",\n  \"pillar\": \"fire_safety | food_safety | vendor | facility | unknown\",\n  \"vendorName\": \"string or null\",\n  \"serviceDate\": \"YYYY-MM-DD or null\",\n  \"expiryDate\": \"YYYY-MM-DD or null\",\n  \"confidence\": 0.0-1.0,\n  \"summary\": \"One-line description of the document\",\n  \"suggestedFields\": {}\n}\n\nRules:\n- If you cannot determine the document type with reasonable confidence \\(>0.5\\), set documentType to \"unknown\".\n- Extract dates in YYYY-MM-DD format. If only a month/year is visible, use the 1st of the month.\n- For vendor names, use the full business name as printed on the document.\n- Do NOT include any text outside the JSON object.`;\n\n    // Build content array for the message\n    const content: any[] = [];\n\n    if \\(isImage\\) {\n      content.push\\({\n        type: \"image\",\n        source: { type: \"base64\", media_type: mimeType, data: fileBase64 },\n      }\\);\n      content.push\\({\n        type: \"text\",\n        text: `Analyze this image of a commercial kitchen compliance document. Classify it and extract all metadata. File name: ${fileName}`,\n      }\\);\n    } else if \\(isPdf\\) {\n      content.push\\({\n        type: \"document\",\n        source: { type: \"base64\", media_type: \"application/pdf\", data: fileBase64 },\n      }\\);\n      content.push\\({\n        type: \"text\",\n        text: `Analyze this PDF compliance document. Classify it and extract all metadata. File name: ${fileName}`,\n      }\\);\n    } else {\n      // Filename-only classification\n      content.push\\({\n        type: \"text\",\n        text: `Classify this commercial kitchen compliance document based on its filename: \"${fileName}\". Do your best to determine the type, but set confidence low if uncertain.`,\n      }\\);\n    }\n\n    // Call Claude API directly \\(same pattern as ai-document-analysis\\)\n    const response = await fetch\\(\"https://api.anthropic.com/v1/messages\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        \"x-api-key\": apiKey,\n        \"anthropic-version\": \"2023-06-01\",\n      },\n      body: JSON.stringify\\({\n        model: \"claude-sonnet-4-5-20250929\",\n        max_tokens: 1024,\n        system: systemPrompt,\n        messages: [{ role: \"user\", content }],\n      }\\),\n    }\\);\n\n    if \\(!response.ok\\) {\n      const errText = await response.text\\(\\);\n      console.error\\(\"Claude API error:\", errText\\);\n      throw new Error\\(`Claude API returned ${response.status}`\\);\n    }\n\n    const result = await response.json\\(\\);\n    const text = result.content\n      .filter\\(\\(b: any\\) => b.type === \"text\"\\)\n      .map\\(\\(b: any\\) => b.text\\)\n      .join\\(\"\"\\);\n\n    // Clean and parse JSON response\n    const cleaned = text.replace\\(/```json\\\\s*|```\\\\s*/g, \"\"\\).trim\\(\\);\n    const classification: ClassificationResult = JSON.parse\\(cleaned\\);\n\n    // Clamp confidence to 0-1 range\n    classification.confidence = Math.max\\(0, Math.min\\(1, classification.confidence\\)\\);\n\n    return new Response\\(\n      JSON.stringify\\({ success: true, classification }\\),\n      { headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n    \\);\n  } catch \\(error\\) {\n    console.error\\(\"Classification error:\", error\\);\n    return new Response\\(\n      JSON.stringify\\({\n        success: false,\n        error: String\\(error\\),\n        classification: {\n          documentType: \"unknown\",\n          documentLabel: \"Unknown Document\",\n          pillar: \"unknown\",\n          vendorName: null,\n          serviceDate: null,\n          expiryDate: null,\n          confidence: 0,\n          summary: \"Unable to classify automatically\",\n          suggestedFields: {},\n        },\n      }\\),\n      { headers: { ...corsHeaders, \"Content-Type\": \"application/json\" } }\n    \\);\n  }\n}\\);\nENDOFFILE)",
      "Bash(findstr:*)",
      "Bash(xargs -I {} sh -c 'git show {}:package.json 2>/dev/null | grep -q . && git show {} --stat | grep -q \"\"Task #57\"\" && echo {}')",
      "Bash(winget upgrade:*)",
      "Bash(npx tsx:*)",
      "Bash(npx playwright:*)",
      "Bash(npx puppeteer:*)",
      "Bash(npx vite --port 5199)",
      "Bash(npx:*)",
      "Bash(npm uninstall:*)"
    ]
  }
}
